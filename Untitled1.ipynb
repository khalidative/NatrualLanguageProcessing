{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U6072707\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.0\n",
      "77.0\n",
      "77.0\n",
      "57.99999999999999\n",
      "81.0\n",
      "80.0\n",
      "Most Informative Features\n",
      "                 idiotic = True              neg : pos    =     12.1 : 1.0\n",
      "                  annual = True              pos : neg    =     10.7 : 1.0\n",
      "               atrocious = True              neg : pos    =     10.5 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.5 : 1.0\n",
      "                 frances = True              pos : neg    =      9.3 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.5 : 1.0\n",
      "                 cunning = True              pos : neg    =      7.0 : 1.0\n",
      "                  sexist = True              neg : pos    =      6.9 : 1.0\n",
      "             silverstone = True              neg : pos    =      6.9 : 1.0\n",
      "                  regard = True              pos : neg    =      6.9 : 1.0\n",
      "              schumacher = True              neg : pos    =      6.7 : 1.0\n",
      "                    mena = True              neg : pos    =      6.3 : 1.0\n",
      "                  suvari = True              neg : pos    =      6.3 : 1.0\n",
      "                  shoddy = True              neg : pos    =      6.3 : 1.0\n",
      "                 singers = True              pos : neg    =      6.3 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.1 : 1.0\n",
      "                 kidding = True              neg : pos    =      5.7 : 1.0\n",
      "                    lame = True              neg : pos    =      5.6 : 1.0\n",
      "                obstacle = True              pos : neg    =      5.6 : 1.0\n",
      "                 unravel = True              pos : neg    =      5.6 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.5 : 1.0\n",
      "                     huh = True              neg : pos    =      5.5 : 1.0\n",
      "                  poorly = True              neg : pos    =      5.3 : 1.0\n",
      "                     ugh = True              neg : pos    =      5.2 : 1.0\n",
      "                  stinks = True              neg : pos    =      5.2 : 1.0\n",
      "              henstridge = True              neg : pos    =      5.2 : 1.0\n",
      "                bothered = True              neg : pos    =      5.2 : 1.0\n",
      "                  canyon = True              neg : pos    =      5.1 : 1.0\n",
      "                     liu = True              neg : pos    =      5.1 : 1.0\n",
      "                   plods = True              neg : pos    =      5.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC,LinearSVC,NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class vote(ClassifierI):\n",
    "    def __init__(self,*classifier):\n",
    "        self._classifier=classifier\n",
    "        \n",
    "    def classify(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifier:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "            \n",
    "        return mode(votes)\n",
    "    \n",
    "    \n",
    "    def confidence(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifier:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "     \n",
    "        choice=votes.count(mode(votes))\n",
    "        return choice/len(votes)    \n",
    "        \n",
    "     \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "documents=[(list(movie_reviews.words(filied)),category)\n",
    "          for category in movie_reviews.categories()\n",
    "          for filied in movie_reviews.fileids(category)]\n",
    "\n",
    "#random.shuffle(documents)\n",
    "\n",
    "all_words=[]\n",
    "for i in movie_reviews.words():\n",
    "    all_words.append(i)\n",
    "    \n",
    "all_words=nltk.FreqDist(all_words)\n",
    "\n",
    "word_feature=list(all_words)[:3000]\n",
    "\n",
    "def words_features(document):\n",
    "    words=set(document)\n",
    "    feature={}\n",
    "    for w in word_feature:\n",
    "        feature[w]=(w in words)\n",
    "    return feature\n",
    "print(all_words[\"stupid\"])\n",
    "#print(words_features(movie_reviews.words('neg/cv000_29416.txt')))\n",
    "feature_set=[(words_features(rev),category) for (rev,category ) in documents]\n",
    "\n",
    "\n",
    "training_set=feature_set[:1900]\n",
    "testing_set=feature_set[1900:]\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "\n",
    "mb_classifier=SklearnClassifier(MultinomialNB())\n",
    "mb_classifier.train(training_set)\n",
    "\n",
    "B_classifier=SklearnClassifier(BernoulliNB())\n",
    "B_classifier.train(training_set)\n",
    "\n",
    "S_classifier=SklearnClassifier(SVC())\n",
    "S_classifier.train(training_set)\n",
    "\n",
    "LS_classifier=SklearnClassifier(LinearSVC())\n",
    "LS_classifier.train(training_set)\n",
    "\n",
    "NS_classifier=SklearnClassifier(NuSVC())\n",
    "NS_classifier.train(training_set)\n",
    "\n",
    "\n",
    "vote_classifier=vote(classifier,mb_classifier,B_classifier,S_classifier,LS_classifier,NS_classifier)\n",
    "\n",
    "\n",
    "#print((nltk.classify.accuracy(vote_classifier,testing_set))*100)\n",
    "\n",
    "\n",
    "print((nltk.classify.accuracy(classifier,testing_set))*100)\n",
    "\n",
    "print((nltk.classify.accuracy(mb_classifier,testing_set))*100)\n",
    "\n",
    "print((nltk.classify.accuracy(B_classifier,testing_set))*100)\n",
    "\n",
    "print((nltk.classify.accuracy(S_classifier,testing_set))*100)\n",
    "\n",
    "print((nltk.classify.accuracy(LS_classifier,testing_set))*100)\n",
    "\n",
    "print((nltk.classify.accuracy(NS_classifier,testing_set))*100)\n",
    "\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "        \n",
    "short_pos=open(r\"C:\\Users\\U6072707\\Desktop\\TensorflowProject\\short_pos.txt\",\"r\").read()\n",
    "\n",
    "#csv.reader(data1)\n",
    "short_neg = open(r\"C:\\Users\\U6072707\\Desktop\\TensorflowProject\\short_neg.txt\",\"r\").read()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )\n",
    "\n",
    "\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = word_tokenize(short_pos)\n",
    "short_neg_words = word_tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "# positive data example:      \n",
    "training_set = featuresets[:10000]\n",
    "testing_set =  featuresets[10000:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a=\"that movie was literrly a stupid movie and i don't like it at all\"\n",
    "text=find_features(a)\n",
    "print(voted_classifier.classify(text),voted_classifier.confidence(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
